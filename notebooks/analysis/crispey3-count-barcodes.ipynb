{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and barcode sequencing reads\n",
    "This script takes paired read (read 1: barcode only (12bp) or barcode+UMI (27bp). read 2: barcode+UMI+staggers) fastq files and does the following:\n",
    "1. trims read 2 adapter sequences to recover barcode+UMI sequence\n",
    "2. merges read 1 and 2 with FLASH\n",
    "3. identifies and counts barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# check number of available cores\n",
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect fastq files for quality control using FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/crispey3/ladder_pilot_feb2021/fastq/fastqc/\n",
    "!fastqc -o ~/crispey3/ladder_pilot_feb2021/fastq/fastqc/ ~/crispey3/ladder_pilot_feb2021/fastq/*fastq.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize FastQC output with MultiQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!multiqc -o ~/crispey3/ladder_pilot_feb2021/fastq/fastqc/ ~/crispey3/ladder_pilot_feb2021/fastq/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed to trim read 2 adapters with cutadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key to map fastq names to output names\n",
    "seqID_to_sampleName = {}\n",
    "sample_key_file = \"/home/users/rang/crispey3/ladder_pilot_feb2021/SampleKey-18146-30.txt\"\n",
    "with open(sample_key_file, 'r') as sample_key:\n",
    "    sample_key.readline() # skip header\n",
    "    for line in sample_key:\n",
    "        seqID, sampleName = line.rstrip().split(\"\\t\")\n",
    "        sampleName = sampleName.replace(\"_\",\"-\")\n",
    "        seqID_to_sampleName[seqID] = sampleName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# working directory with fastq files\n",
    "working_dir=\"/home/users/rang/crispey3/ladder_pilot_feb2021/fastq/\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "# get read 2 files for trimming\n",
    "fastq_list = sorted([os.path.abspath(x) for x in glob.glob(\"*R2_001.fastq.gz\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutadapt parameters to trim read 2 to get barcode+UMI (27bp)\n",
    "adapter_5prime = 'GGCCAGTTTAAACTT'\n",
    "adapter_3prime = 'GCATGGC'\n",
    "num_of_cores = 4 #len(os.sched_getaffinity(0))\n",
    "err = 0.2 # fraction tolerated for adapter matching\n",
    "barcode_len = 27 # barcode (12bp) + SphI site (6bp) + UMI (9bp)\n",
    "output_dir_name = 'trimmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store sample key in regex pattern\n",
    "pattern = re.compile('|'.join(seqID_to_sampleName.keys()))\n",
    "\n",
    "# trim read 2, filter untrimmed read pairs\n",
    "for fastq_path in fastq_list:\n",
    "    fastq_dir = os.path.dirname(fastq_path)\n",
    "    output_dir = fastq_dir + \"/\"+output_dir_name+\"/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # rename output files by sample key stored in seqID_to_sampleName \n",
    "    fastq_file = os.path.basename(fastq_path)\n",
    "    output_file_r2 = pattern.sub(lambda x: seqID_to_sampleName[x.group()], fastq_file).replace(\"_001.fastq.gz\", \"_001_trimmed.fastq.gz\") #fastq_file.replace(\"_001.fastq.gz\", \"_001_trimmed.fastq.gz\")\n",
    "    output_file_r1 = output_file_r2.replace(\"_R2_\", \"_R1_\")\n",
    "\n",
    "    print('Trimming: ' + fastq_path)\n",
    "    \n",
    "    cutadapt_cmd = [\"cutadapt\", \"-g\", adapter_5prime+\"...\"+adapter_3prime, \n",
    "                    \"-j\", str(num_of_cores), \n",
    "                    \"-e\", str(err), \n",
    "                    \"-q\", \"20\", # use -q for miseq/hiseq quality trimming\n",
    "                    #\"--nextseq-trim\", \"20\", # use this option for nextseq quality trimming\n",
    "                    \"--discard-untrimmed\", \"-m\", str(barcode_len), \n",
    "                    \"--pair-filter=first\", \n",
    "                    \"-o\", output_dir+output_file_r2, \"-p\", output_dir+output_file_r1,\n",
    "                    fastq_path, fastq_path.replace(\"L001_R2_\", \"L001_R1_\")]\n",
    "    \n",
    "    subprocess.run(cutadapt_cmd)\n",
    "\n",
    "    print(\"Output files:\")\n",
    "    print(output_file_r2)\n",
    "    print(output_file_r1)\n",
    "    print()\n",
    "    \n",
    "print('Done trimming!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge read 1 and read 2 with FLASH to produce final barcode+UMI sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir=\"/home/users/rang/crispey3/ladder_pilot_feb2021/fastq/trimmed/\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "fastq_list = sorted([os.path.abspath(x) for x in glob.glob(\"*R1_001_trimmed.fastq.gz\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLASH parameters\n",
    "min_overlap = 14 # this number should be no greater than the length of the shorter read\n",
    "max_mismatch = 0.25\n",
    "output_dir_name = 'merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use FLASH to merge trimmed-filtered read 2 and read 1 data to produce final 27bp sequence containing barcode and UMI data\n",
    "for fastq_path in fastq_list:\n",
    "    fastq_dir = os.path.dirname(fastq_path)\n",
    "    output_dir = fastq_dir + \"/\"+output_dir_name+\"/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    output_prefix = os.path.basename(fastq_path).split(\"_\")[0]+\"_barcode\" # check output file naming \n",
    "    print('Merging', fastq_path, 'and', fastq_path.replace(\"_R1_\", \"_R2_\"))\n",
    "    \n",
    "    flash_cmd = [\"flash\", \"-m\", str(min_overlap), \n",
    "                 \"-x\", str(max_mismatch), \"-O\", # use -O if innie-only merging does not work\n",
    "                 \"-o\", output_prefix, \"-d\", output_dir, \n",
    "                 \"--compress\", \n",
    "                 fastq_path, fastq_path.replace(\"_R1_\", \"_R2_\")]\n",
    "    subprocess.run(flash_cmd)\n",
    "    print(output_prefix, \"merged\")\n",
    "\n",
    "print('Done merging!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Trim back merged read to desired barcode length\n",
    "If read 1 was sequenced longer than the barcode+UMI, trim the merged read back to the correct length. This step is not required if read 1 is shorter than barcode length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim merged read to desired barcode length\n",
    "barcode_length = 27\n",
    "\n",
    "working_dir=\"/home/users/rang/crispey3/ladder_pilot_feb2021/fastq/trimmed/merged\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "fastq_list = sorted([os.path.abspath(x) for x in glob.glob(\"*barcode.extendedFrags.fastq.gz\")])\n",
    "\n",
    "for fastq_path in fastq_list:\n",
    "    output_path = fastq_path.replace(\".extendedFrags\", \"_final\")\n",
    "    cutadapt_cmd = [\"cutadapt\", \"-l\", str(barcode_length),\n",
    "                    \"-o\", output_path, fastq_path]\n",
    "    \n",
    "    subprocess.run(cutadapt_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Downsample reads for analysis\n",
    "Use seqtk in command line to downsample fastq files prior to assembling counts matrix.<br>\n",
    "e.g. seqtk sample -s100 read1.fq 10000 > sub1.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count barcodes\n",
    "Counting barcodes consists of several steps. For each read:\n",
    "1. Filter reads that are too long/short, or contain N's\n",
    "2. Extract barcode and UMI sequences\n",
    "3. Assign barcode-UMI ID according to reference lists of barcodes and UMIs\n",
    "4. Count barcode by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_barcodes(fastq_file, sample_name, barcode_table, umi_list,\n",
    "                   min_seq_length=20, barcode_length=12, umi_length=9, linker_seq='GCATGC'):\n",
    "    '''\n",
    "    parses a fastq file, extracts barcode and UMI sequences and identifies ID according to reference table\n",
    "    in each sequence, barcodes and UMIs can be extracted by removing the middle linker sequence\n",
    "    barcodes and UMIs are ID-ed using error tolerant regex. Error tolerance is set according to minimum Hamming\n",
    "    distance between designed barcode and UMI sequences. Adjust accordingly.\n",
    "    ID'ed barcodes are counted and its counts returned as a dict.\n",
    "    \n",
    "    length parameters should be adjusted based on what is included in the fastq reads. For example, if the reads contain\n",
    "    only barcode sequence without UMIs or linker, set umi_length=0 and linker_seq=''.\n",
    "    \n",
    "    to exclude umi info and counting, set umi_list = []\n",
    "    '''\n",
    "    barcode_counts_dict = {}\n",
    "    \n",
    "    # set max_seq_length\n",
    "    max_seq_length = barcode_length+umi_length+len(linker_seq) # this could be adjusted to allow insertions\n",
    "    # alphabetical sort umi_list\n",
    "    umi_list = sorted(umi_list)\n",
    "    \n",
    "    # parse fastq\n",
    "    with gzip.open(fastq_file, 'rt') as fastq:\n",
    "        for read in SeqIO.parse(fastq, \"fastq\"):\n",
    "            barcode, umi, barcode_id, umi_id, final_id = [''] * 5\n",
    "            \n",
    "            # extract barcode and UMI sequence from read\n",
    "            # filter for barcodes within min/max barcode length and contains no N's\n",
    "            if min_seq_length <= len(read.seq) <= max_seq_length and read.seq.count(\"N\")==0:\n",
    "                sequence = str(read.seq)\n",
    "                \n",
    "                # split sequence to get barcode and UMI sequences\n",
    "                try:\n",
    "                    # assumes no error in linker sequence\n",
    "                    barcode, umi = sequence.split(linker_seq) # error tolerant regex is possible, but risks conflicting with barcode/UMI. is there a better way?\n",
    "                except ValueError:\n",
    "                    # if linker seq cannot be found (possibly sequencing error) or yields multiple splits,\n",
    "                    # fall back to splitting by base position. Assumes UMI and linker have no indels\n",
    "                    if umi_length == 0:\n",
    "                        umi = ''\n",
    "                        barcode = sequence[:barcode_length]\n",
    "                    else:\n",
    "                        umi = sequence[-umi_length:]\n",
    "                        barcode = sequence[:-(umi_length+len(linker_seq))] # for shorter sequences, partial barcodes are retrieved and can still be potentially ID-ed\n",
    "                        \n",
    "                # skip read if barcode or UMI is too short\n",
    "                if len(barcode)<barcode_length/2 or len(umi)<umi_length/2:\n",
    "                    print(\"Skipping {}: Barcode/UMI too short\".format(sequence))\n",
    "                    continue\n",
    "                    \n",
    "            else:\n",
    "#                 print(\"Skipping {}: Read does not pass filter\".format(read.seq))\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # assign barcode ID to final ID\n",
    "            # first search for barcode with exact match. If not possible, use error-tolerant regex\n",
    "            try:\n",
    "                barcode_id = barcode_table.loc[barcode, 'Unique_ID']\n",
    "            except KeyError:\n",
    "                error=len(barcode)//5 # max error allowed: 0.2\n",
    "                search = [bool(regex.search(barcode+'{e<='+str(error)+'}', x)) for x in barcode_table.index]\n",
    "                if sum(search)==1:\n",
    "                    barcode_id = barcode_table.loc[search, 'Unique_ID']\n",
    "                else:\n",
    "                    # skip read if barcode cannot be identified\n",
    "                    print(\"Skipping {}: Unable to assign barcode ID\".format(sequence))\n",
    "                    continue\n",
    "            # add barcode ID to final ID\n",
    "            final_id = barcode_id\n",
    "            \n",
    "            \n",
    "            # assign UMI ID and append to final ID (if applicable)\n",
    "            # first search for UMI with exact match in UMI list. assign number based on order in sorted UMI list\n",
    "            # If not possible, use error-tolerant regex to assign\n",
    "            if len(umi)>0 and len(umi_list)>0:\n",
    "                try:\n",
    "                    umi_id = umi_list.index(umi)+1\n",
    "                except ValueError:\n",
    "                    error=len(umi)//4 # max error allowed: 0.25\n",
    "                    search = [bool(regex.search(umi+'{e<='+str(error)+'}', x)) for x in umi_list]\n",
    "                    if sum(search) == 1:\n",
    "                        umi_id = search.index(True)+1\n",
    "                    else:\n",
    "                        # skip read if UMI cannot be identified\n",
    "                        print(\"Skipping {}: Unable to assign UMI ID\".format(sequence))\n",
    "                        continue\n",
    "                            \n",
    "                # add UMI ID to final ID\n",
    "                final_id = '-'.join([final_id, str(umi_id)])\n",
    "\n",
    "            \n",
    "            # add newly assigned barcode-UMI to counts\n",
    "            try:\n",
    "                barcode_counts_dict[final_id] += 1\n",
    "            except KeyError:\n",
    "                barcode_counts_dict[final_id] = 1\n",
    "    \n",
    "    \n",
    "    return barcode_counts_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir=\"/home/users/rang/crispey3/ladder_pilot_feb2021/fastq/trimmed/merged/\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "# merged reads to count barcodes from\n",
    "fastq_list = sorted(glob.glob(\"*barcode_final*\")) # check for file name\n",
    "# sample names for each fastq\n",
    "sample_name_list = [fastq_file.split(\"_\")[0] for fastq_file in fastq_list] # adjust accordingly to generate sample name for counts matrix\n",
    "\n",
    "#output directory\n",
    "output_dir = \"/home/users/rang/crispey3/ladder_pilot_feb2021/counts/\"\n",
    "\n",
    "# counts file\n",
    "counts_filename = \"all_barcode_counts.txt\"\n",
    "\n",
    "\n",
    "# open barcode reference file\n",
    "barcode_reference_file = '/home/users/rang/crispey3/library_design/Input/12BP_PBCs_well_grouped.csv'\n",
    "barcode_table = pd.read_csv(barcode_reference_file, index_col=1)\n",
    "\n",
    "# approved list of UMIs used in cloning CRISPEY3 plasmid\n",
    "umi_list = ['ACGCGTGAA',\n",
    "            'ATGTGGCTC',\n",
    "            'CAGAGGATC',\n",
    "            'CTGTGGCAA',\n",
    "            'GTGTGATTC',\n",
    "            'TAGAGGACT']\n",
    "umi_list = sorted(umi_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and count barcodes for each fastq file\n",
    "fastq_dict = dict(zip(sample_name_list, fastq_list))\n",
    "with mp.Pool(min(len(os.sched_getaffinity(0)), len(fastq_list))) as pool:\n",
    "    all_counts_df = {sample_name : pool.apply_async(count_barcodes, (fastq_file, sample_name, barcode_table, umi_list)) for sample_name, fastq_file in fastq_dict.items()}\n",
    "    all_counts_df = {sample_name : res.get() for sample_name, res in all_counts_df.items()}\n",
    "    \n",
    "# write all counts to output file\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "all_counts_df = pd.DataFrame.from_dict(all_counts_df, orient=\"columns\")\n",
    "all_counts_df.index.name = 'barcode'\n",
    "all_counts_df.to_csv(output_dir+counts_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Combine counts across UMIs per barcode\n",
    "The counts of different UMIs of the same barcode can be added together to produce a stacked counts matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine counts from different UMIs of the same barcode\n",
    "stacked_counts_filename = \"stacked_barcode_counts.txt\"\n",
    "\n",
    "stacked_counts_df = all_counts_df.groupby(by=lambda x: x.split('-')[0]).sum()\n",
    "stacked_counts_df.to_csv(output_dir+stacked_counts_filename, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crispey-bar)",
   "language": "python",
   "name": "crispey-bar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
